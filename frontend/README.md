## 📱 Frontend (React Native / Expo)

SoriBom의 프론트엔드는 **실시간 음성 수집 → 서버 처리 → 사용자 피드백**의 전 과정을 연결하는 사용자 접점으로,
접근성과 실시간성을 최우선으로 설계되었습니다.

### 🔄 프론트엔드 역할 요약

* 지하철 안내방송 **실시간 녹음 및 10초 단위 업로드**
* 키워드 감지 시 **즉각적인 사용자 알림 제공**
* 서버 처리 완료 후 **요약 정보 및 방송 이력 시각화**
* 세션 기반 흐름 제어로 **녹음 / 결과 조회 명확히 분리**

---

### 🎙️ 실시간 음성 녹음 및 업로드 구조

* Expo Audio API를 사용하여 음성을 녹음
* 음성은 **10초 단위 chunk**로 분할되어 서버(`/audio/`)에 업로드
* 최대 녹음 시간(90초) 제한을 두어 사용자 제어 안정성 확보
* 네트워크 지연 상황에서도 녹음이 끊기지 않도록 설계

> 이 구조를 통해 서버는 스트리밍에 가까운 방식으로 음성을 처리할 수 있으며,
> 프론트엔드는 녹음 중에도 UI 응답성을 유지합니다.

---

### 🔔 키워드 알림 시스템

프론트엔드는 **SSE 알림 구조**를 사용합니다.

#### 1️⃣ SSE 기반 실시간 알림

* 서버에서 키워드 감지 시 `/session/{id}/stream/`으로 이벤트 전송
* 프론트엔드는 SSE 스트림을 구독하여 즉시 이벤트 수신
* 수신 즉시 **OS 알림(expo-notifications)** 발송

---

### 🧠 세션 기반 상태 관리 구조

프론트엔드는 모든 동작을 **세션 단위로 명확히 분리**합니다.

* `sessionId`
  → 현재 녹음 중인 세션
* `lastSessionId`
  → 방금 종료된 세션 (결과 조회 전용)

녹음 종료 시:

1. 현재 세션을 `lastSessionId`로 보관
2. 새로운 세션을 생성하여 다음 녹음을 준비
3. 사용자가 등록한 키워드는 새 세션에 자동 재등록

이를 통해 **녹음 데이터와 결과 데이터가 섞이지 않도록 설계**되었습니다.

---

### 📊 결과 조회 및 시각화

* 서버 처리 상태를 `/status/` API로 확인
* 상태가 `COMPLETE`가 되면 `/results/` API 호출
* 결과는 전역 Context에 저장하여 **중복 API 호출 방지**

#### UI 구성

* **CoreInfo**

  * 가장 최근 안내방송의 핵심 정보(역명, 출입문, 환승, 주의사항) 표시
  * 서버가 제공한 구조화 데이터(`info`)만 사용
* **BroadcastHistory**

  * 전체 안내방송 타임라인 표시
  * 키워드가 감지된 방송은 강조 표시 및 키워드 칩 제공
  * 클라이언트 측 키워드 비교 없이 **서버 판단 결과만 신뢰**

---

### ♿ 접근성 및 사용자 경험 고려

* 실시간 알림으로 중요한 정보 즉시 전달
* 복잡한 설정 없이도 사용 가능한 단순 UI 흐름
* 음성에 의존하지 않고 **텍스트 기반 정보 제공**
* 청각장애인 및 소음 환경 사용자 모두를 고려한 설계

---
