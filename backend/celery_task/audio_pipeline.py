# celery_task/audio_pipeline.py

import sys
from celery import shared_task
from django.utils import timezone
import torch

from ai_modules.separator.inference import load_custom_model, run_model
from ai_modules.utils.audio import load_wav_tensor
from ai_modules.stt.whisper_stt import run_stt

from recordings.models import Session, AudioChunk, Broadcast
from keywords.models import Keyword, Alert


# ----------------------------------------------------------
# ğŸ”’ Django ê´€ë¦¬ ëª…ë ¹ ì‹¤í–‰ ì¤‘(migrate ë“±)ì—ëŠ” ëª¨ë¸ ë¡œë“œ ê¸ˆì§€
# ----------------------------------------------------------

if (
    "migrate" in sys.argv
    or "makemigrations" in sys.argv
    or "collectstatic" in sys.argv
    or "check" in sys.argv
    or "shell" in sys.argv
):
    print("[INFO] Django ì´ˆê¸°í™” ë‹¨ê³„ â†’ separator ëª¨ë¸ ë¡œë“œ ìƒëµ")
    separator_model = None
else:
    print("[INFO] Separator ëª¨ë¸ ë¡œë“œ ì¤‘...")
    separator_model = load_custom_model()
    print("[INFO] Separator ëª¨ë¸ ë¡œë”© ì™„ë£Œ")


# ----------------------------------------------------------
# ğŸ§  Celery Task: Chunk ì²˜ë¦¬
# ----------------------------------------------------------

@shared_task
def process_audio_chunk(chunk_id):
    try:
        chunk = AudioChunk.objects.get(id=chunk_id)
        session = chunk.session
        chunk.status = "PROCESSING"
        chunk.save()

        # 1. ì›ë³¸ ì˜¤ë””ì˜¤ ë¡œë“œ
        wav_tensor, sr = load_wav_tensor(chunk.file_path)

        # 2. ì•ˆë‚´ë°©ì†¡ ë¶„ë¦¬ (ëª¨ë¸ì´ ì¡´ì¬í•˜ëŠ” ê²½ìš°ì—ë§Œ)
        if separator_model:
            try:
                clean_tensor = run_model(separator_model, wav_tensor, DEVICE)
            except Exception as e:
                print("[WARN] separator inference ì‹¤íŒ¨ â†’ ì›ë³¸ ì˜¤ë””ì˜¤ ì‚¬ìš©:", e)
                clean_tensor = wav_tensor
        else:
            clean_tensor = wav_tensor

        # 3. Whisper STT
        text, confidence = run_stt(clean_tensor)

        # 4. Broadcast ìƒì„±
        broadcast = Broadcast.objects.create(
            session=session,
            audio_chunk=chunk,
            full_text=text,
            confidence_avg=confidence,
        )

        # 5. í‚¤ì›Œë“œ ê°ì§€
        keywords = Keyword.objects.filter(session=session)
        for kw in keywords:
            if kw.word in text:
                broadcast.keywords_detected.add(kw)
                Alert.objects.create(keyword=kw, broadcast=broadcast)

        # 6. ì„¸ì…˜ progress ì¦ê°€
        session.progress = min(session.progress + 10, 100)
        session.save()

        # 7. Chunk ì™„ë£Œ
        chunk.status = "COMPLETE"
        chunk.save()

    except Exception as e:
        chunk = AudioChunk.objects.get(id=chunk_id)
        chunk.status = "ERROR"
        chunk.save()
        print(f"[ERROR] chunk {chunk_id} ì²˜ë¦¬ ì‹¤íŒ¨:", e)
